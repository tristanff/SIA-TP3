{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f16fe86e-8ef7-481d-a0aa-9fb0094f398d",
   "metadata": {},
   "source": [
    "## Preparing Data and Initial Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c77228f3-4ac6-40b9-bfb9-bfa69e9fc05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from perceptron import LinealPerceptron, HiperbolicPerceptron, LogisticPerceptron\n",
    "\n",
    "def get_data():\n",
    "    data = pd.read_csv('TP3-ej2-conjunto.csv')  \n",
    "    input_data = np.array(data[['x1', 'x2', 'x3']])  # Input features\n",
    "    expected_data = np.array(data['y'])  # Expected outputs\n",
    "    return input_data, expected_data\n",
    "\n",
    "\n",
    "input_data, expected_data = get_data()\n",
    "\n",
    "# Hyperparameters\n",
    "bias = 1\n",
    "error_threshold = 0.0001\n",
    "max_epochs = 10000\n",
    "beta = 1  \n",
    "\n",
    "train_ratio = 0.8  # 80% for training, 20% for testing\n",
    "split_index = int(len(input_data) * train_ratio)\n",
    "\n",
    "training_data = input_data[:split_index].tolist()  \n",
    "testing_data = input_data[split_index:].tolist()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3323b96-5bab-414a-b740-ed6a1dfae3ea",
   "metadata": {},
   "source": [
    "## Learning rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d695bc-a5e7-4005-825f-0aa9890d792e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T21:42:50.714886Z",
     "start_time": "2024-05-03T21:24:59.903450Z"
    }
   },
   "outputs": [],
   "source": [
    "input_size=3\n",
    "num_iterations = 10\n",
    "learning_rates = [0.0001, 0.001, 0.01]\n",
    "\n",
    "# Utility function to pad arrays to the same length\n",
    "def extend_to_max_length(values, max_length):\n",
    "    return np.pad(values, (0, max_length - len(values)), 'edge')\n",
    "\n",
    "# Function to run experiments and save results\n",
    "def run_experiments_and_save_to_csv(filename):\n",
    "    results = []\n",
    "    \n",
    "    # Run for Linear Perceptron\n",
    "    for lr in learning_rates:\n",
    "        all_mse = []  # List to store MSE for all iterations\n",
    "        max_length = 0  # To track the longest MSE sequence\n",
    "        for _ in range(num_iterations):\n",
    "            linear_perceptron = LinealPerceptron(lr, [], bias, input_size, error_threshold)\n",
    "            epochs, train_errors, test_errors = linear_perceptron.train(\n",
    "                training_data, testing_data, expected_data[:split_index], expected_data[split_index:], max_epochs\n",
    "            )\n",
    "            mse = (np.array(train_errors) + np.array(test_errors)) / 2\n",
    "            all_mse.append(mse)\n",
    "            max_length = max(max_length, len(mse))  # Track the maximum length\n",
    "        \n",
    "        all_mse = [extend_to_max_length(m, max_length) for m in all_mse]\n",
    "        avg_mse = np.mean(np.array(all_mse), axis=0)  # Calculate the average MSE\n",
    "        \n",
    "        # Save the results for each epoch\n",
    "        for epoch, mse in enumerate(avg_mse):\n",
    "            results.append({'Perceptron Type': 'Linear', 'Learning Rate': lr, 'Epoch': epoch, 'MSE': mse})\n",
    "    \n",
    "    # Run for Hyperbolic Perceptron\n",
    "    for lr in learning_rates:\n",
    "        all_mse = []\n",
    "        max_length = 0\n",
    "        for _ in range(num_iterations):\n",
    "            hiperbolic_perceptron = HiperbolicPerceptron(beta, lr, [], bias, input_size, error_threshold)\n",
    "            epochs, train_errors, test_errors = hiperbolic_perceptron.train(\n",
    "                training_data, testing_data, expected_data[:split_index], expected_data[split_index:], max_epochs\n",
    "            )\n",
    "            mse = (np.array(train_errors) + np.array(test_errors)) / 2\n",
    "            all_mse.append(mse)\n",
    "            max_length = max(max_length, len(mse))\n",
    "        \n",
    "        all_mse = [extend_to_max_length(m, max_length) for m in all_mse]\n",
    "        avg_mse = np.mean(np.array(all_mse), axis=0)  # Calculate the average MSE\n",
    "        \n",
    "        # Save the results for each epoch\n",
    "        for epoch, mse in enumerate(avg_mse):\n",
    "            results.append({'Perceptron Type': 'Hyperbolic', 'Learning Rate': lr, 'Epoch': epoch, 'MSE': mse})\n",
    "    \n",
    "    # Run for Logistic Perceptron\n",
    "    for lr in learning_rates:\n",
    "        all_mse = []\n",
    "        max_length = 0\n",
    "        for _ in range(num_iterations):\n",
    "            logistic_perceptron = LogisticPerceptron(beta, lr, [], bias, input_size, error_threshold)\n",
    "            epochs, train_errors, test_errors = logistic_perceptron.train(\n",
    "                training_data, testing_data, expected_data[:split_index], expected_data[split_index:], max_epochs\n",
    "            )\n",
    "            mse = (np.array(train_errors) + np.array(test_errors)) / 2\n",
    "            all_mse.append(mse)\n",
    "            max_length = max(max_length, len(mse))\n",
    "        \n",
    "        all_mse = [extend_to_max_length(m, max_length) for m in all_mse]\n",
    "        avg_mse = np.mean(np.array(all_mse), axis=0)  # Calculate the average MSE\n",
    "        \n",
    "        # Save the results for each epoch\n",
    "        for epoch, mse in enumerate(avg_mse):\n",
    "            results.append({'Perceptron Type': 'Logistic', 'Learning Rate': lr, 'Epoch': epoch, 'MSE': mse})\n",
    "    \n",
    "    # Convert results to DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(filename, index=False)  # Save to CSV\n",
    "\n",
    "# Save the data to a CSV\n",
    "csv_filename = 'MSE_By_LR-Epochs.csv'\n",
    "run_experiments_and_save_to_csv(csv_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa061a16119a550",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T22:09:38.879455Z",
     "start_time": "2024-05-06T22:09:38.693711Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read the CSV and plot the data\n",
    "results_df = pd.read_csv('MSE_By_LR-Epochs.csv')\n",
    "\n",
    "# Create a figure with three subplots\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot for the Linear Perceptron\n",
    "plt.subplot(1, 3, 1)\n",
    "linear_data = results_df[results_df['Perceptron Type'] == 'Linear']\n",
    "for lr in learning_rates:\n",
    "    data_for_lr = linear_data[linear_data['Learning Rate'] == lr]\n",
    "    avg_mse = data_for_lr.groupby('Epoch')['MSE'].mean()  # Calculate the average MSE\n",
    "    plt.plot(avg_mse.index, avg_mse.values, label=f'LR = {lr}')  # Plot the average MSE\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.ylabel(\"Mean Squared Error (MSE)\")\n",
    "plt.title(\"Linear Perceptron\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot for the Hyperbolic Perceptron\n",
    "plt.subplot(1, 3, 2)\n",
    "hyperbolic_data = results_df[results_df['Perceptron Type'] == 'Hyperbolic']\n",
    "for lr in learning_rates:\n",
    "    data_for_lr = hyperbolic_data[hyperbolic_data['Learning Rate'] == lr]\n",
    "    avg_mse = data_for_lr.groupby('Epoch')['MSE'].mean()  # Calculate the average MSE\n",
    "    plt.plot(avg_mse.index, avg_mse.values, label=f'LR = {lr}')  # Plot the average MSE\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.ylabel(\"Mean Squared Error (MSE)\")\n",
    "plt.title(\"Hyperbolic Perceptron\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot for the Logistic Perceptron\n",
    "plt.subplot(1, 3, 3)\n",
    "logistic_data = results_df[results_df['Perceptron Type'] == 'Logistic']\n",
    "for lr in learning_rates:\n",
    "    data_for_lr = logistic_data[logistic_data['Learning Rate'] == lr]\n",
    "    avg_mse = data_for_lr.groupby('Epoch')['MSE'].mean()  # Calculate the average MSE\n",
    "    plt.plot(avg_mse.index, avg_mse.values, label=f'LR = {lr}')  # Plot the average MSE\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.ylabel(\"Mean Squared Error (MSE)\")\n",
    "plt.title(\"Logistic Perceptron\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()  # Display the plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcc11b5-a87e-4cf7-89a6-d6bf03ebb294",
   "metadata": {},
   "source": [
    "We can see that the Hyperbolic and Logistic Perceptron are way better than the Linear percepetron on this dataSet. The better one is the Hyperbolic Perceptron. A litlle learning rate will make the training slower. Maybe it will allow to have better performance of the perceptron but we want to keep a good ratio of compute/Performance so we will "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8591ce-acdd-49d0-ad1b-35ba1f954832",
   "metadata": {},
   "source": [
    "## Learning Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ad8c5f-2703-4206-b358-88e05ac1e02a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T21:50:22.996762Z",
     "start_time": "2024-05-03T21:50:22.972889Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from perceptron import LinealPerceptron, HiperbolicPerceptron, LogisticPerceptron\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    data = pd.read_csv('TP3-ej2-conjunto.csv')  \n",
    "    input_data = np.array(data[['x1', 'x2', 'x3']])  # Input features\n",
    "    expected_data = np.array(data['y'])  # Expected outputs\n",
    "    return input_data, expected_data\n",
    "\n",
    "input_data, expected_data = get_data()\n",
    "\n",
    "input_size = 3\n",
    "\n",
    "# Hyperparameters\n",
    "bias = 1\n",
    "error_threshold = 0.0001\n",
    "max_epochs = 10000\n",
    "beta = 1\n",
    "# Define a split ratio for training and testing data\n",
    "train_ratio = 0.8  # 80% for training, 20% for testing\n",
    "split_index = int(len(input_data) * train_ratio)\n",
    "\n",
    "training_data = input_data[:split_index].tolist()  # Training data\n",
    "testing_data = input_data[split_index:].tolist()  # Testing data\n",
    "learning_rate = 0.01  # Fixed learning rate\n",
    "training_ratios = [0.6, 0.7, 0.8, 0.9]  # Different training ratios\n",
    "num_iterations = 10  # Number of iterations to average over\n",
    "\n",
    "\n",
    "# Utility function to pad arrays to the same length\n",
    "def extend_to_max_length(values, max_length):\n",
    "    return np.pad(values, (0, max_length - len(values)), 'edge')\n",
    "\n",
    "\n",
    "def run_experiments_with_ratios(filename):\n",
    "    results = []\n",
    "\n",
    "    # Loop through each training ratio\n",
    "    for train_ratio in training_ratios:\n",
    "        split_index = int(len(input_data) * train_ratio)\n",
    "        training_data = input_data[:split_index].tolist()  # Training data\n",
    "        testing_data = input_data[split_index:].tolist()  # Testing data\n",
    "\n",
    "        # Linear Perceptron\n",
    "        all_mse = []\n",
    "        max_length = 0\n",
    "        for i in range(num_iterations):\n",
    "            linear_perceptron = LinealPerceptron(learning_rate, [], bias, input_size, error_threshold)\n",
    "            epochs, train_errors, test_errors = linear_perceptron.train(\n",
    "                training_data, testing_data, expected_data[:split_index], expected_data[split_index:], max_epochs\n",
    "            )\n",
    "            print(f\"Epochs For Lineal iteration {i} : {epochs}\\n\")\n",
    "            mse = (np.array(train_errors) + np.array(test_errors)) / 2\n",
    "            all_mse.append(mse)\n",
    "            max_length = max(max_length, len(mse))\n",
    "\n",
    "        all_mse = [extend_to_max_length(m, max_length) for m in all_mse]\n",
    "        avg_mse = np.mean(np.array(all_mse), axis=0)\n",
    "\n",
    "        for epoch, mse in enumerate(avg_mse):\n",
    "            results.append({\n",
    "                'Perceptron Type': 'Linear',\n",
    "                'Training Ratio': train_ratio,\n",
    "                'Epoch': epoch,\n",
    "                'MSE': mse\n",
    "            })\n",
    "\n",
    "        # Hyperbolic Perceptron\n",
    "        all_mse = []\n",
    "        max_length = 0\n",
    "        for i in range(num_iterations):\n",
    "            hiperbolic_perceptron = HiperbolicPerceptron(beta, learning_rate, [], bias, input_size, error_threshold)\n",
    "            epochs, train_errors, test_errors = hiperbolic_perceptron.train(\n",
    "                training_data, testing_data, expected_data[:split_index], expected_data[split_index:], max_epochs\n",
    "            )\n",
    "            print(f\"Epochs For Hyperbolic iteration {i} : {epochs}\\n\")\n",
    "            mse = (np.array(train_errors) + np.array(test_errors)) / 2\n",
    "            all_mse.append(mse)\n",
    "            max_length = max(max_length, len(mse))\n",
    "\n",
    "        all_mse = [extend_to_max_length(m, max_length) for m in all_mse]\n",
    "        avg_mse = np.mean(np.array(all_mse), axis=0)\n",
    "\n",
    "        for epoch, mse in enumerate(avg_mse):\n",
    "            results.append({\n",
    "                'Perceptron Type': 'Hyperbolic',\n",
    "                'Training Ratio': train_ratio,\n",
    "                'Epoch': epoch,\n",
    "                'MSE': mse\n",
    "            })\n",
    "\n",
    "        # Logistic Perceptron\n",
    "        all_mse = []\n",
    "        max_length = 0\n",
    "        for i in range(num_iterations):\n",
    "            logistic_perceptron = LogisticPerceptron(beta, learning_rate, [], bias, input_size, error_threshold)\n",
    "            epochs, train_errors, test_errors = logistic_perceptron.train(\n",
    "                training_data, testing_data, expected_data[:split_index], expected_data[split_index:], max_epochs\n",
    "            )\n",
    "            #print(f\"Epochs For Logistic iteration {i} : {epochs}\\n\")\n",
    "            mse = (np.array(train_errors) + np.array(test_errors)) / 2\n",
    "            all_mse.append(mse)\n",
    "            max_length = max(max_length, len(mse))\n",
    "\n",
    "        all_mse = [extend_to_max_length(m, max_length) for m in all_mse]\n",
    "        avg_mse = np.mean(np.array(all_mse), axis=0)\n",
    "\n",
    "        for epoch, mse in enumerate(avg_mse):\n",
    "            results.append({\n",
    "                'Perceptron Type': 'Logistic',\n",
    "                'Training Ratio': train_ratio,\n",
    "                'Epoch': epoch,\n",
    "                'MSE': mse\n",
    "            })\n",
    "\n",
    "    # Save results to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(filename, index=False)  # Save to CSV\n",
    "\n",
    "run_experiments_with_ratios('MSE_byTrainRatio-Epochs.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c226a68-0619-4464-875e-b2b2c0093340",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T20:03:47.690229Z",
     "start_time": "2024-05-06T20:03:47.497829Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read CSV and create plots\n",
    "csv_filename = 'MSE_byTrainRatio-Epochs.csv'\n",
    "results_df = pd.read_csv(csv_filename)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "\n",
    "training_ratios = [0.6, 0.7, 0.8, 0.9]  # Different training ratios\n",
    "\n",
    "# Create plots for each perceptron type and training ratio\n",
    "for perceptron_type in ['Linear', 'Hyperbolic', 'Logistic']:\n",
    "    plt.subplot(3, 1, ['Linear', 'Hyperbolic', 'Logistic'].index(perceptron_type) + 1)\n",
    "    data_for_type = results_df[results_df['Perceptron Type'] == perceptron_type]\n",
    "    \n",
    "    for train_ratio in training_ratios:\n",
    "        data_for_ratio = data_for_type[data_for_type['Training Ratio'] == train_ratio]\n",
    "        avg_mse = data_for_ratio.groupby('Epoch')['MSE'].mean()\n",
    "        \n",
    "        plt.plot(avg_mse.index, avg_mse.values, label=f'Ratio = {train_ratio}')\n",
    "    \n",
    "    plt.xlabel(\"Number of epochs\")\n",
    "    plt.ylabel(\"Mean Squared Error (MSE)\")\n",
    "    plt.title(f\"{perceptron_type} Perceptron\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()  # Display the plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8283c1-87fb-43d1-93ce-466a79f88731",
   "metadata": {},
   "source": [
    "## Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd5fa26-c2ea-475b-b1c2-1ac16e19fb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from perceptron import LinealPerceptron, HiperbolicPerceptron, LogisticPerceptron\n",
    "\n",
    "# Fonction pour obtenir les données\n",
    "def get_data():\n",
    "    data = pd.read_csv('TP3-ej2-conjunto.csv')  # Changez cela avec votre fichier CSV\n",
    "    input_data = np.array(data[['x1', 'x2', 'x3']])  # Variables d'entrée\n",
    "    expected_data = np.array(data['y'])  # Sorties attendues\n",
    "    return input_data, expected_data\n",
    "\n",
    "# Obtenir les données\n",
    "input_data, expected_data = get_data()\n",
    "\n",
    "# Paramètres\n",
    "train_ratio = 0.8  # Ratio de formation fixe\n",
    "split_index = int(len(input_data) * train_ratio)\n",
    "training_data = input_data[:split_index].tolist()  # Données d'entraînement\n",
    "testing_data = input_data[split_index:].tolist()  # Données de test\n",
    "\n",
    "# Hyperparamètres\n",
    "input_size = 3\n",
    "bias = 1\n",
    "error_threshold = 0.0001\n",
    "max_epochs = 10000\n",
    "learning_rate = 0.01  # Taux d'apprentissage fixe\n",
    "betas = [0.1, 0.5, 1, 2, 5]  # Liste des valeurs de beta\n",
    "num_iterations = 10  # Nombre d'itérations pour la moyenne\n",
    "\n",
    "# Fonction utilitaire pour étendre les tableaux à la même longueur\n",
    "def extend_to_max_length(values, max_length):\n",
    "    return np.pad(values, (0, max_length - len(values)), 'edge')\n",
    "\n",
    "# Fonction pour exécuter les expériences avec différentes valeurs de beta pour différents perceptrons\n",
    "def run_experiments_with_betas(filename):\n",
    "    results = []\n",
    "\n",
    "    for beta in betas:\n",
    "        # Pour le Perceptron Linéaire\n",
    "        all_mse = []\n",
    "        max_length = 0\n",
    "        for _ in range(num_iterations):\n",
    "            linear_perceptron = LinealPerceptron(learning_rate, [], bias, input_size, error_threshold)\n",
    "            epochs, train_errors, test_errors = linear_perceptron.train(\n",
    "                training_data, testing_data, expected_data[:split_index], expected_data[split_index:], max_epochs\n",
    "            )\n",
    "            mse = (np.array(train_errors) + np.array(test_errors)) / 2\n",
    "            all_mse.append(mse)\n",
    "            max_length = max(max_length, len(mse))\n",
    "\n",
    "        all_mse = [extend_to_max_length(m, max_length) for m in all_mse]\n",
    "        avg_mse = np.mean(np.array(all_mse), axis=0)\n",
    "\n",
    "        for epoch, mse in enumerate(avg_mse):\n",
    "            results.append({\n",
    "                'Perceptron Type': 'Linear',\n",
    "                'Beta': beta,\n",
    "                'Epoch': epoch,\n",
    "                'MSE': mse\n",
    "            })\n",
    "\n",
    "        # Pour le Perceptron Hyperbolique\n",
    "        all_mse = []\n",
    "        max_length = 0\n",
    "        for _ in range(num_iterations):\n",
    "            hiperbolic_perceptron = HiperbolicPerceptron(beta, learning_rate, [], bias, input_size, error_threshold)\n",
    "            epochs, train_errors, test_errors = hiperbolic_perceptron.train(\n",
    "                training_data, testing_data, expected_data[:split_index], expected_data[split_index:], max_epochs\n",
    "            )\n",
    "            mse = (np.array(train_errors) + np.array(test_errors)) / 2\n",
    "            all_mse.append(mse)\n",
    "            max_length = max(max_length, len(mse))\n",
    "\n",
    "        all_mse = [extend_to_max_length(m, max_length) for m in all_mse]\n",
    "        avg_mse = np.mean(np.array(all_mse), axis=0)\n",
    "\n",
    "        for epoch, mse in enumerate(avg_mse):\n",
    "            results.append({\n",
    "                'Perceptron Type': 'Hyperbolic',\n",
    "                'Beta': beta,\n",
    "                'Epoch': epoch,\n",
    "                'MSE': mse\n",
    "            })\n",
    "\n",
    "        # Pour le Perceptron Logistique\n",
    "        all_mse = []\n",
    "        max_length = 0\n",
    "        for _ in range(num_iterations):\n",
    "            logistic_perceptron = LogisticPerceptron(beta, learning_rate, [], bias, input_size, error_threshold)\n",
    "            epochs, train_errors, test_errors = logistic_perceptron.train(\n",
    "                training_data, testing_data, expected_data[:split_index], expected_data[split_index:], max_epochs\n",
    "            )\n",
    "            mse = (np.array(train_errors) + np.array(test_errors)) / 2\n",
    "            all_mse.append(mse)\n",
    "            max_length = max(max_length, len(mse))\n",
    "\n",
    "        all_mse = [extend_to_max_length(m, max_length) for m in all_mse]\n",
    "        avg_mse = np.mean(np.array(all_mse), axis=0)\n",
    "\n",
    "        for epoch, mse in enumerate(avg_mse):\n",
    "            results.append({\n",
    "                'Perceptron Type': 'Logistic',\n",
    "                'Beta': beta,\n",
    "                'Epoch': epoch,\n",
    "                'MSE': mse\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(filename, index=False)  # Enregistrer dans un CSV\n",
    "\n",
    "# Exécuter les expériences et sauvegarder les résultats\n",
    "csv_filename = 'MSE_byBeta-Epochs.csv'\n",
    "run_experiments_with_betas(csv_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48701b31c7bc978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Lire les résultats du CSV\n",
    "results_df = pd.read_csv('MSE_byBeta-Epochs.csv')\n",
    "\n",
    "perceptron_types = results_df['Perceptron Type'].unique()\n",
    "betas = results_df['Beta'].unique()\n",
    "\n",
    "# Create a plot for each perceptron type\n",
    "for perceptron_type in perceptron_types:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Filter data by perceptron type\n",
    "    perceptron_results = results_df[results_df['Perceptron Type'] == perceptron_type]\n",
    "\n",
    "    # Plot MSE for each beta value\n",
    "    for beta in betas:\n",
    "        # Filter data for the specific beta\n",
    "        beta_results = perceptron_results[perceptron_results['Beta'] == beta]\n",
    "\n",
    "        # Plotting\n",
    "        plt.plot(beta_results['Epoch'], beta_results['MSE'], label=f'Beta = {beta}')\n",
    "\n",
    "    # Adding labels and title\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.title(f'MSE by Number of Epochs for {perceptron_type}')\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eb5903-16b3-454f-8feb-50ec221ff284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1da997b-f0cb-4b76-9441-a341a8873d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
